---
title: 使用Ollama部署本地大模型
date: 2024-12-05 22:21:58
tags:
  - AI 
categories:
  - Tech
---

在AI逐渐火热的今天，没有一个属于自己的本地大模型怎么行呢，今天来教你使用Ollma快速搭建一个利用本地算力的聊天网站，支持多种本地模型，效果如图:

![](https://raw.githubusercontent.com/fogsong233/imgbed/main/2024/12/05-22-43-28-2024-12-05-22-42-04-image.png)

### 硬件要求

作者的电脑是Windows 11，显卡是RTX 4060，推荐有显卡的电脑安装，如果你的显卡内存少于16gb，建议使用参数在7B左右的模型，不然对话会生成的很慢。同时你需要保证你有能访问Github等网站的环境。

### 安装Ollama

> 什么是OIlama?  

<img src="https://raw.githubusercontent.com/fogsong233/imgbed/main/2024/12/05-22-48-20-ollama.png" title="" alt="" data-align="center">

一个羊驼为logo的软件，它拥有一个集成了各种常见开源大模型的网络库，通过这个软件你可以很方便的下载模型并配置一些基础设置，本文我们直接使用它下载下来的模型就好了。

打开Ollama官网，[Download Ollama](https://ollama.com/download)，下载对应的系统程序（这里以Windows为例子），双击下载下来的OllamaSetup.exe，进行安装。

> 注意，在windows下安装时，是不允许选择安装位置的，默认是安装在系统盘的。 

安装完毕后，打开终端进行验证，在终端中输入`ollama`。

如果看到以下信息则说明安装成功

![](https://raw.githubusercontent.com/fogsong233/imgbed/main/2024/12/05-22-56-50-2024-12-05-22-56-42-image.png)

#### 设置模型安装位置

因为模型动辄几十GB，所以最好把模型放到D盘或者E盘，不然你的C盘会迅速爆红。这需要你创建一个储存目录(如下面代码里的`D:\ollama_models`，然后设置Windows终端的环境变量。

```shell
# 只设置当前用户（需要先创建D:\ollama_models目录）
setx OLLAMA_MODELS "D:\ollama_models" 
# 为所有用户设置（需要先创建D:\ollama_models目录）
setx OLLAMA_MODELS "D:\ollama_models" /M
```

之后重启这个终端和Ollama服务就好了。

### Ollama的模型

可以通过以下网址查看Ollama支持的模型列表：  [Ollama Library](https://ollama.com/library)

![](https://raw.githubusercontent.com/fogsong233/imgbed/main/2024/12/05-23-03-04-2024-12-05-23-02-58-image.png)

现在我们不需要安装，因为Ollama是个命令行程序，它提供了一个后端，但是我们想要想ChatGPT或是Kimi一样聊天的话，我们需要一个网页前端。

### 部署网页前端

我们使用[Open Web UI](https://github.com/open-webui/open-webui)这个开源AI聊天前端，这需要你安装Python（什么？你没有安装Python？）。确保你有Python的包管理工具`Pip`，输入：

```shell
pip install open-webui
```

这样你就成功安装了！接着输入`open-webui serve`启动前端，它会输出一个网址（应该是 [http://localhost:8080](http://localhost:8080/) ）。访问如果出现页面，你就成功启动啦！

### 配置你的模型

首先确保你的Ollama在后台运行，在命令行中输入`ollama serve`，他会返回你一个网址，（大概是127.0.0.1:11434)，这是所有模型运行的后端的访问地址，我们需要把他关联到前端去。

访问Open WebUI，找到管理员设置，找到模型

![](https://raw.githubusercontent.com/fogsong233/imgbed/main/2024/12/05-23-14-49-2024-12-05-23-14-44-image.png)

在`管理Ollama模型`这个选项里找到Ollama返回的网址(或者是输入)。然后再访问Ollama Library找到你想要的模型，输入`模型名:参数`（比如`qwen:7B`）。然后点击右边的下载按钮。等待自动下载，你也可以下载多个模型，下载完后返回主页，可以自主切换模型。

![](https://raw.githubusercontent.com/fogsong233/imgbed/main/2024/12/05-23-18-51-2024-12-05-23-18-44-image.png)

之后就可以开始聊天啦！

### 更多操作

#### 自定义系统提示词

想要让你的AI更加智能？你可以配置预设的提示词，点击右上角的配置小图标打开对话高级设置，你可以输入系统提示词，帮助更好的分析的你的问题。

![](https://raw.githubusercontent.com/fogsong233/imgbed/main/2024/12/05-23-21-25-2024-12-05-23-21-21-image.png)

比如这个开源项目[GitHub - bklieger-groq/g1](https://github.com/bklieger-groq/g1) 就可以实现类似ChatGPT o1思维链的效果。

#### 使用记忆或者角色扮演

![](https://raw.githubusercontent.com/fogsong233/imgbed/main/2024/12/05-23-26-39-2024-12-05-23-26-35-image.png)

在管理员设置里，你可以设置记忆为大模型输入预设预料，也可以点击头像，找到AI对话游乐场，为你的AI添加角色预设！

![](https://raw.githubusercontent.com/fogsong233/imgbed/main/2024/12/05-23-28-49-2024-12-05-23-28-46-image.png)

#### 更多设置

访问Open Web UI或Ollama官网来获取更多自定义设置，或者你可以访问[Hugging Face]([https://huggingface.co/](https://huggingface.co/))，探索更多大模型的世界！
